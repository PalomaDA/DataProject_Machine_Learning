{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcbb0c6a",
   "metadata": {},
   "source": [
    "# PREPROCESAMIENTO DE DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81bdae84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scr.explore_utils import null_analysis, column_type_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5255c27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuramos que se muestren todas las columnas de nuestros dataframes\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95bd5ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\i'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\i'\n",
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_17180\\676143788.py:1: SyntaxWarning: invalid escape sequence '\\i'\n",
      "  df = pd.read_csv(\"files\\input\\dataset_estudiantes.csv\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"files\\input\\dataset_estudiantes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af1db776",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(str.upper, axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf4e34a",
   "metadata": {},
   "source": [
    "## 1. Gestión de duplicados\n",
    "\n",
    "### Plan de acción\n",
    "Según el EDA, no se detectaron valores duplicados en el dataset. Sin embargo, es importante verificar nuevamente antes de proceder con el modelado. Si se detectan duplicados, se evaluará si son registros idénticos que deben eliminarse o si representan casos legítimos (aunque poco probable en este contexto)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1307e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe9876a3",
   "metadata": {},
   "source": [
    "## 2. Gestión de valores nulos\n",
    "\n",
    "### Plan de acción\n",
    "Según el EDA, se identificaron valores faltantes en tres variables que requieren imputación:\n",
    "\n",
    "- **HORAS_SUENO** (15% faltantes, 150 registros):\n",
    "  - Estrategia recomendada: Imputación por mediana (7.02 horas) o mediante modelo predictivo (KNN Imputer, Random Forest Imputer)\n",
    "  - Justificación: La distribución es relativamente normal y centrada alrededor de 7 horas, la mediana es robusta a outliers\n",
    "  \n",
    "- **HORARIO_ESTUDIO_PREFERIDO** (10% faltantes, 100 registros):\n",
    "  - Estrategia recomendada: Imputación por moda (categoría más frecuente: \"Noche\") o crear categoría \"Desconocido\"\n",
    "  - Alternativa: Modelo predictivo basado en otras variables (ej: estilo de aprendizaje, horas de estudio)\n",
    "  \n",
    "- **ESTILO_APRENDIZAJE** (5% faltantes, 50 registros):\n",
    "  - Estrategia recomendada: Imputación por moda (categoría más frecuente: \"Visual\") o crear categoría \"Desconocido\"\n",
    "  - Alternativa: Modelo predictivo\n",
    "\n",
    "**Implementación**: Probar ambas estrategias (imputación simple vs modelo predictivo) y comparar el impacto en el rendimiento del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e0fad9",
   "metadata": {},
   "source": [
    "## 3. Gestión de valores atípicos (outliers)\n",
    "\n",
    "### Plan de acción\n",
    "Según el EDA, se detectaron outliers en las siguientes variables:\n",
    "\n",
    "- **TASA_ASISTENCIA**: 4 outliers detectados (0.4% del total) mediante método IQR\n",
    "  - Estrategia: Revisar si son errores de datos o valores válidos\n",
    "  - Si son válidos: Mantener (son pocos y pueden ser informativos)\n",
    "  - Si son errores: Eliminar o capar (winsorization) a los límites del IQR\n",
    "  \n",
    "- **HORAS_ESTUDIO_SEMANAL**: Revisar valores extremos (rango 1-25 horas)\n",
    "  - Validar si valores muy bajos (<2 horas) o muy altos (>20 horas) son realistas\n",
    "  - Considerar capar si son errores de medición\n",
    "\n",
    "**Implementación**: \n",
    "1. Analizar cada outlier individualmente para determinar si es un error o un valor válido\n",
    "2. Si son errores, aplicar winsorization o eliminación según corresponda\n",
    "3. Documentar las decisiones tomadas para cada caso"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed5a5c8",
   "metadata": {},
   "source": [
    "## 4. Codificación de variables categóricas (encoding)\n",
    "\n",
    "### Plan de acción\n",
    "Según el EDA, tenemos 4 variables categóricas que requieren encoding. La estrategia dependerá de si existe un orden natural en las categorías:\n",
    "\n",
    "- **NIVEL_DIFICULTAD** (3 categorías: Fácil, Medio, Difícil):\n",
    "  - Estrategia: **Ordinal Encoding** (Fácil=0, Medio=1, Difícil=2)\n",
    "  - Justificación: Existe un orden lógico y el EDA muestra diferencias graduales en el rendimiento según el nivel\n",
    "  \n",
    "- **TIENE_TUTOR** (2 categorías: Sí, No):\n",
    "  - Estrategia: **Binary Encoding** (Sí=1, No=0)\n",
    "  - Justificación: Variable binaria simple\n",
    "  \n",
    "- **HORARIO_ESTUDIO_PREFERIDO** (3 categorías: Mañana, Tarde, Noche):\n",
    "  - Estrategia: **One-Hot Encoding** (3 columnas binarias)\n",
    "  - Justificación: No hay un orden natural claro entre los horarios\n",
    "  \n",
    "- **ESTILO_APRENDIZAJE** (4 categorías: Visual, Auditivo, Lectura/Escritura, Kinestésico):\n",
    "  - Estrategia: **One-Hot Encoding** (4 columnas binarias)\n",
    "  - Justificación: No hay un orden natural entre los estilos\n",
    "\n",
    "**Implementación**: \n",
    "- Usar `OrdinalEncoder` de scikit-learn para NIVEL_DIFICULTAD\n",
    "- Usar `LabelEncoder` o mapeo manual para TIENE_TUTOR\n",
    "- Usar `OneHotEncoder` o `pd.get_dummies()` para HORARIO_ESTUDIO_PREFERIDO y ESTILO_APRENDIZAJE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49236432",
   "metadata": {},
   "source": [
    "## 5. Estandarización de las variables numéricas\n",
    "\n",
    "### Plan de acción\n",
    "La necesidad de escalado/normalización depende del tipo de modelo que se vaya a utilizar:\n",
    "\n",
    "**Modelos que REQUIEREN escalado:**\n",
    "- Modelos basados en distancias: KNN, SVM\n",
    "- Redes neuronales\n",
    "- Modelos con regularización: Ridge, Lasso, Elastic Net\n",
    "- Análisis de componentes principales (PCA)\n",
    "\n",
    "**Modelos que NO requieren escalado:**\n",
    "- Árboles de decisión\n",
    "- Random Forest\n",
    "- Gradient Boosting (XGBoost, LightGBM, CatBoost)\n",
    "- Naive Bayes\n",
    "\n",
    "**Métodos de escalado recomendados:**\n",
    "- **StandardScaler** (media=0, std=1): Para distribuciones relativamente normales. Apropiado para la mayoría de nuestras variables numéricas según el EDA\n",
    "- **MinMaxScaler** (rango 0-1): Si queremos mantener la interpretabilidad y el rango original\n",
    "- **RobustScaler**: Si hay presencia de outliers (usa mediana e IQR en lugar de media y desviación estándar)\n",
    "\n",
    "**Implementación**: \n",
    "- Crear pipelines que permitan activar/desactivar el escalado según el modelo\n",
    "- Aplicar el escalado SOLO después de dividir train/test para evitar data leakage\n",
    "- Guardar los parámetros del scaler del conjunto de entrenamiento para aplicar la misma transformación al test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce441561",
   "metadata": {},
   "source": [
    "## 6. Selección de variables (feature selection)\n",
    "\n",
    "### Plan de acción\n",
    "Según el EDA, se identificaron variables con baja o nula correlación con las variables objetivo:\n",
    "\n",
    "**Variables a considerar eliminar:**\n",
    "- **EDAD**: \n",
    "  - Correlación prácticamente nula (-0.01) con NOTA_FINAL\n",
    "  - Sin diferencias significativas entre aprobados y suspendidos (ambos con mediana de 24 años)\n",
    "  - Recomendación: Mantener inicialmente para validación, eliminar si no mejora el modelo\n",
    "  \n",
    "- **HORAS_SUENO**: \n",
    "  - Correlación muy débil (0.07) con NOTA_FINAL\n",
    "  - Sin diferencias significativas entre aprobados (mediana: 7.01) y suspendidos (mediana: 7.05)\n",
    "  - Además tiene 15% de valores faltantes\n",
    "  - Recomendación: Mantener inicialmente para validación, eliminar si no mejora el modelo\n",
    "\n",
    "**Variables a mantener** (alta predictividad):\n",
    "- **HORAS_ESTUDIO_SEMANAL**: Correlación 0.51 con NOTA_FINAL, diferencia de 5.17 horas entre aprobados/suspendidos\n",
    "- **NOTA_ANTERIOR**: Correlación 0.47 con NOTA_FINAL, diferencia de 12.49 puntos entre aprobados/suspendidos\n",
    "- **TASA_ASISTENCIA**: Correlación 0.32 con NOTA_FINAL, diferencia de 14.44 puntos porcentuales\n",
    "- **TIENE_TUTOR**: Diferencia de 10 puntos porcentuales en tasa de aprobado\n",
    "- **Todas las variables categóricas**: Muestran impacto en los objetivos según el EDA\n",
    "\n",
    "**Feature Engineering - Interacciones sugeridas:**\n",
    "- `HORAS_ESTUDIO_SEMANAL × TIENE_TUTOR`: ¿El tutor multiplica el efecto de las horas de estudio?\n",
    "- `NOTA_ANTERIOR × NIVEL_DIFICULTAD`: ¿La dificultad percibida modera el efecto de la nota anterior?\n",
    "- `TASA_ASISTENCIA × HORAS_ESTUDIO_SEMANAL`: Efecto sinérgico de asistencia y estudio\n",
    "\n",
    "**Implementación**: \n",
    "- Probar modelos con y sin EDAD y HORAS_SUENO para comparar rendimiento\n",
    "- Crear features de interacción para las combinaciones sugeridas\n",
    "- Usar técnicas de selección de features (SelectKBest, Recursive Feature Elimination) si el número de features crece significativamente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f86d74",
   "metadata": {},
   "source": [
    "## 7. Preparación específica para REGRESIÓN (NOTA_FINAL)\n",
    "\n",
    "### Plan de acción\n",
    "Para el modelo de regresión que predice NOTA_FINAL:\n",
    "\n",
    "**Preparación de la variable objetivo:**\n",
    "- **NOTA_FINAL**: Variable continua (rango 30-100)\n",
    "- El EDA muestra distribución relativamente normal (media: 71.44, mediana: 71.4, std: 9.56)\n",
    "- Probablemente no necesite transformación, pero validar distribución de residuos según modelo elegido\n",
    "\n",
    "**División Train/Test/Validation:**\n",
    "- División recomendada: 70% train, 15% validation, 15% test\n",
    "- Estratificar NO es necesario (variable continua)\n",
    "- Asegurar que la distribución de NOTA_FINAL sea similar en todos los sets (verificar estadísticas descriptivas)\n",
    "\n",
    "**Consideraciones adicionales:**\n",
    "- No se requiere balanceo de clases (es regresión)\n",
    "- Validar supuestos del modelo según el algoritmo elegido (normalidad de residuos, homocedasticidad, etc.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2ae2c8",
   "metadata": {},
   "source": [
    "## 8. Preparación específica para CLASIFICACIÓN (APROBADO)\n",
    "\n",
    "### Plan de acción\n",
    "Para el modelo de clasificación que predice APROBADO:\n",
    "\n",
    "**Balanceo de Clases (CRÍTICO):**\n",
    "- **Problema detectado**: Desbalance severo (89.8% aprobados vs 10.2% suspendidos)\n",
    "- Este es el paso MÁS IMPORTANTE para clasificación, ya que sin balanceo el modelo tendrá sesgo hacia la clase mayoritaria\n",
    "\n",
    "**Estrategias a probar y comparar:**\n",
    "1. **SMOTE** (Synthetic Minority Oversampling Technique):\n",
    "   - Generar muestras sintéticas de la clase minoritaria (suspendidos)\n",
    "   - Ventaja: Aumenta la clase minoritaria sin perder información\n",
    "   - Implementación: `imbalanced-learn` library (`SMOTE()`)\n",
    "\n",
    "2. **Ajuste de pesos en el modelo**:\n",
    "   - Usar `class_weight='balanced'` en modelos de scikit-learn\n",
    "   - Ajustar manualmente pesos según ratio: {0: 8.98, 1: 1.02} (aproximado)\n",
    "   - Ventaja: No modifica los datos, solo ajusta la función de costo\n",
    "\n",
    "3. **Combinación SMOTE + Tomek Links**:\n",
    "   - SMOTE para oversampling + Tomek Links para limpieza de muestras\n",
    "   - Puede mejorar la calidad de las muestras sintéticas\n",
    "\n",
    "4. **Undersampling** (menos recomendado):\n",
    "   - Reducir la clase mayoritaria\n",
    "   - Riesgo: Pérdida de información valiosa\n",
    "   - Solo considerar si el dataset es muy grande\n",
    "\n",
    "**Métricas de evaluación apropiadas:**\n",
    "- ❌ NO usar **Accuracy** (será engañoso, siempre predecirá \"Aprobado\")\n",
    "- ✅ Usar: **Precision**, **Recall**, **F1-score**, **ROC-AUC**, **Matriz de confusión**\n",
    "- Priorizar **Recall de la clase minoritaria** (suspendidos) si es crítico detectarlos\n",
    "\n",
    "**División Train/Test/Validation:**\n",
    "- División recomendada: 70% train, 15% validation, 15% test\n",
    "- **IMPORTANTE**: Estratificar por APROBADO para mantener proporciones en todos los sets\n",
    "- **CRÍTICO**: Aplicar balanceo SOLO en el conjunto de entrenamiento, NO en validation/test\n",
    "\n",
    "**Preparación de la variable objetivo:**\n",
    "- **APROBADO**: Variable binaria (0=Suspenso, 1=Aprobado)\n",
    "- Verificar que esté como tipo int o bool\n",
    "- Ya está en formato correcto según el EDA\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
